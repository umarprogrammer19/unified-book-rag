"use strict";(globalThis.webpackChunkbook_source=globalThis.webpackChunkbook_source||[]).push([[7144],{8453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>l});var o=t(6540);const i={},s=o.createContext(i);function r(e){const n=o.useContext(s);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),o.createElement(s.Provider,{value:n},e.children)}},9124:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>h,frontMatter:()=>r,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"Module 07 The-Capstone/7.1-the-capstone-project","title":"Chapter 7: The Capstone - Conversational Robot","description":"This capstone project brings together all the concepts learned in the \\"Teaching Physical AI & Humanoid Robotics Course\\" to build a conversational robot. The goal is to create an embodied AI that can understand natural language, process information, and perform actions in a physical or simulated environment.","source":"@site/docs/Module 07 The-Capstone/7.1-the-capstone-project.md","sourceDirName":"Module 07 The-Capstone","slug":"/Module 07 The-Capstone/7.1-the-capstone-project","permalink":"/docs/Module 07 The-Capstone/7.1-the-capstone-project","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/Module 07 The-Capstone/7.1-the-capstone-project.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 6: Navigation & SLAM - ROS 2 Nav2 Setup Guide","permalink":"/docs/Module 06 Navigation-SLAM/6.4-ros2-nav2-setup-guide"}}');var i=t(4848),s=t(8453);const r={},l="Chapter 7: The Capstone - Conversational Robot",a={},c=[{value:"1. Conversational Robot Architecture",id:"1-conversational-robot-architecture",level:2},{value:"Architecture Overview: User Speaks -&gt; Whisper (STT) -&gt; GPT-4o (Brain) -&gt; ROS 2 (Action)",id:"architecture-overview-user-speaks---whisper-stt---gpt-4o-brain---ros-2-action",level:3},{value:"2. Project Guide for Students: Building Your Conversational Robot",id:"2-project-guide-for-students-building-your-conversational-robot",level:2},{value:"Phase 1: Setup and Core Components",id:"phase-1-setup-and-core-components",level:3},{value:"Phase 2: Embodiment and Action",id:"phase-2-embodiment-and-action",level:3},{value:"Phase 3: Testing, Refinement, and Physical Deployment",id:"phase-3-testing-refinement-and-physical-deployment",level:3},{value:"3. Final CAARE Program Capstone Presentation Rubric",id:"3-final-caare-program-capstone-presentation-rubric",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"chapter-7-the-capstone---conversational-robot",children:"Chapter 7: The Capstone - Conversational Robot"})}),"\n",(0,i.jsx)(n.p,{children:'This capstone project brings together all the concepts learned in the "Teaching Physical AI & Humanoid Robotics Course" to build a conversational robot. The goal is to create an embodied AI that can understand natural language, process information, and perform actions in a physical or simulated environment.'}),"\n",(0,i.jsx)(n.h2,{id:"1-conversational-robot-architecture",children:"1. Conversational Robot Architecture"}),"\n",(0,i.jsx)(n.p,{children:"The core architecture for our conversational robot will follow a modular design, enabling clear separation of concerns and integration of state-of-the-art AI and robotics technologies."}),"\n",(0,i.jsx)(n.h3,{id:"architecture-overview-user-speaks---whisper-stt---gpt-4o-brain---ros-2-action",children:"Architecture Overview: User Speaks -> Whisper (STT) -> GPT-4o (Brain) -> ROS 2 (Action)"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"User Speaks (Input)"}),": The interaction begins with the user's spoken commands or questions."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Whisper (Speech-to-Text - STT)"}),": NVIDIA Whisper, or a similar robust speech-to-text model, will transcribe the user's spoken input into text. This ensures accurate conversion of audio into a format suitable for the LLM."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"GPT-4o (Brain - Natural Language Understanding & Decision Making)"}),': The transcribed text is then fed into a large language model like GPT-4o. This model acts as the robot\'s "brain," performing:',"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Natural Language Understanding (NLU)"}),": Interpreting the intent and entities from the user's query."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Cognitive Processing"}),": Generating responses, making decisions, and planning actions based on its understanding and contextual awareness."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Action Command Generation"}),": Translating high-level intentions into specific, structured commands that can be executed by the robot's control system."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"ROS 2 (Robot Operating System 2 - Action Execution)"}),": The structured commands generated by GPT-4o are then interfaced with ROS 2. ROS 2 nodes will be responsible for:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Perception"}),": Utilizing sensor data (cameras, LIDAR, IMUs) to understand the environment."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Navigation"}),": Planning and executing movements to reach target locations."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Manipulation"}),": Controlling robotic arms and grippers to interact with objects."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Speech Synthesis (TTS)"}),": Converting the robot's textual responses from GPT-4o back into spoken language to respond to the user."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"2-project-guide-for-students-building-your-conversational-robot",children:"2. Project Guide for Students: Building Your Conversational Robot"}),"\n",(0,i.jsx)(n.p,{children:"This guide provides a roadmap for students to develop their own conversational robot."}),"\n",(0,i.jsx)(n.h3,{id:"phase-1-setup-and-core-components",children:"Phase 1: Setup and Core Components"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"ROS 2 Environment Setup"}),":","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Install Ubuntu 22.04 LTS on your Digital Twin Workstation (RTX 4070 Ti+ GPU, Intel i7 13th Gen+ CPU, 64 GB RAM)."}),"\n",(0,i.jsx)(n.li,{children:"Install ROS 2 Humble/Iron."}),"\n",(0,i.jsx)(n.li,{children:"Set up your NVIDIA Jetson Orin Nano (8GB) Edge Kit with necessary ROS 2 packages."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Speech-to-Text Integration (Whisper)"}),":","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Explore available ROS 2 packages for speech recognition (e.g., integrating an on-device Whisper model or a cloud-based API)."}),"\n",(0,i.jsx)(n.li,{children:"Connect your ReSpeaker USB Mic Array v2.0 to your Jetson or workstation."}),"\n",(0,i.jsx)(n.li,{children:"Develop a ROS 2 node to capture audio, process it with Whisper, and publish the transcribed text to a ROS topic."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"LLM Integration (GPT-4o)"}),":","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Set up API access for GPT-4o."}),"\n",(0,i.jsx)(n.li,{children:"Develop a ROS 2 node that subscribes to the transcribed text topic, sends it to GPT-4o, and receives the response."}),"\n",(0,i.jsx)(n.li,{children:"Design the prompt engineering for GPT-4o to ensure it generates actionable commands and relevant conversational responses."}),"\n",(0,i.jsx)(n.li,{children:"Consider tools like Function Calling to allow GPT-4o to directly invoke robot actions."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Text-to-Speech Integration"}),":","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Integrate a text-to-speech (TTS) engine (e.g., Google Text-to-Speech, MaryTTS, or a local model) to convert GPT-4o's textual responses into spoken feedback for the user."}),"\n",(0,i.jsx)(n.li,{children:"Develop a ROS 2 node to publish audio commands to your speaker."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"phase-2-embodiment-and-action",children:"Phase 2: Embodiment and Action"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Robot Simulation (Gazebo/Isaac Sim)"}),":","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Load your chosen robot's URDF/SDF model into Gazebo or NVIDIA Isaac Sim."}),"\n",(0,i.jsx)(n.li,{children:"Familiarize yourself with simulating its sensors (Intel RealSense D435i/D455 for RGB-D, LIDAR)."}),"\n",(0,i.jsx)(n.li,{children:"Develop basic ROS 2 control nodes for the robot's movement (e.g., simple locomotion, joint control)."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Action Mapping (GPT-4o to ROS 2)"}),":","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:['Define a clear mapping between GPT-4o\'s generated commands and ROS 2 actions (e.g., "move forward" -> ',(0,i.jsx)(n.code,{children:"/cmd_vel"}),' topic, "pick up object" -> sequence of manipulation actions).']}),"\n",(0,i.jsx)(n.li,{children:"Implement ROS 2 action servers/clients for complex tasks like navigation and manipulation."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Interaction Design"}),":","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Focus on natural human-robot interaction."}),"\n",(0,i.jsx)(n.li,{children:"Implement safeguards and error handling for ambiguous or impossible commands."}),"\n",(0,i.jsx)(n.li,{children:"Consider multi-modal feedback beyond speech, such as visual cues in the simulation or on the physical robot."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"phase-3-testing-refinement-and-physical-deployment",children:"Phase 3: Testing, Refinement, and Physical Deployment"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Unit and Integration Testing"}),":","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Rigorously test each component (STT, LLM, TTS, ROS 2 control) independently and in integrated workflows."}),"\n",(0,i.jsx)(n.li,{children:"Use ROS 2 launch files to manage complex system startups for testing."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Sim-to-Real Transfer"}),":","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"If using a physical robot (Unitree Go2 Edu, Hiwonder TonyPi Pro, etc.), transfer your tested ROS 2 nodes from simulation to the Jetson Orin Nano."}),"\n",(0,i.jsx)(n.li,{children:"Address any discrepancies or challenges that arise from the sim-to-real gap."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"User Trials & Iteration"}),":","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Conduct user trials to gather feedback on the robot's conversational abilities and task performance."}),"\n",(0,i.jsx)(n.li,{children:"Iterate on prompt engineering for GPT-4o and refine ROS 2 action mappings based on user feedback."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"3-final-caare-program-capstone-presentation-rubric",children:"3. Final CAARE Program Capstone Presentation Rubric"}),"\n",(0,i.jsx)(n.p,{children:"The final presentation for your conversational robot capstone will be evaluated on the following criteria:"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{style:{textAlign:"left"},children:"Category"}),(0,i.jsx)(n.th,{style:{textAlign:"left"},children:"Description"}),(0,i.jsx)(n.th,{style:{textAlign:"left"},children:"Weighting"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{style:{textAlign:"left"},children:(0,i.jsx)(n.strong,{children:"I. Problem Definition & Goals"})}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"Clearly articulate the problem your conversational robot addresses. Define the specific goals and objectives of your capstone project, including what constitutes success."}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"15%"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{style:{textAlign:"left"},children:(0,i.jsx)(n.strong,{children:"II. Architecture Design"})}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"Present a comprehensive overview of your robot's architecture (User -> Whisper -> GPT-4o -> ROS 2). Justify key architectural choices, including the selection of specific AI models (STT, LLM, TTS) and their integration with ROS 2 for perception and action."}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"20%"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{style:{textAlign:"left"},children:(0,i.jsx)(n.strong,{children:"III. Implementation & Development"})}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"Demonstrate the core functionality of your conversational robot. Show evidence of robust implementation, including code structure, use of ROS 2 concepts (nodes, topics, services, actions), and integration of AI components. Highlight any novel solutions or challenges overcome."}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"25%"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{style:{textAlign:"left"},children:(0,i.jsx)(n.strong,{children:"IV. Demonstration & Performance"})}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"Conduct a live demonstration (simulated or physical) of your conversational robot. Showcase its ability to understand commands, engage in conversation, and perform actions. Discuss performance metrics, error handling, and reliability."}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"20%"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{style:{textAlign:"left"},children:(0,i.jsx)(n.strong,{children:"V. Future Work & Impact"})}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"Discuss potential future enhancements, extensions, or improvements to your robot. Articulate the broader impact and implications of your work within the field of Physical AI and humanoid robotics."}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"10%"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{style:{textAlign:"left"},children:(0,i.jsx)(n.strong,{children:"VI. Presentation Clarity & Engagement"})}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"Present your work clearly, concisely, and engagingly. Effectively answer questions from the audience, demonstrating a deep understanding of your project."}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:"10%"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{style:{textAlign:"left"},children:(0,i.jsx)(n.strong,{children:"Total"})}),(0,i.jsx)(n.td,{style:{textAlign:"left"}}),(0,i.jsx)(n.td,{style:{textAlign:"left"},children:(0,i.jsx)(n.strong,{children:"100%"})})]})]})]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}}}]);