"use strict";(globalThis.webpackChunkbook_source=globalThis.webpackChunkbook_source||[]).push([[849],{6164:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"category","label":"Module 01 Hardware-Lab","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/Module 01 Hardware-Lab/1.1-physical-ai-foundations-basics","label":"Chapter 1: Foundations of Physical AI & Lab Setup","docId":"Module 01 Hardware-Lab/1.1-physical-ai-foundations-basics","unlisted":false},{"type":"link","href":"/docs/Module 01 Hardware-Lab/1.2-digital-twin-workstation-setup","label":"1.2-digital-twin-workstation-setup","docId":"Module 01 Hardware-Lab/1.2-digital-twin-workstation-setup","unlisted":false},{"type":"link","href":"/docs/Module 01 Hardware-Lab/1.3-physical-ai-edge-kit","label":"1.3-physical-ai-edge-kit","docId":"Module 01 Hardware-Lab/1.3-physical-ai-edge-kit","unlisted":false},{"type":"link","href":"/docs/Module 01 Hardware-Lab/1.4-lab-options-hybrid-architectures","label":"1.4-lab-options-hybrid-architectures","docId":"Module 01 Hardware-Lab/1.4-lab-options-hybrid-architectures","unlisted":false}]},{"type":"category","label":"Module 02 ROS2-Basics","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/Module 02 ROS2-Basics/2.1-ros2-core-concepts","label":"Chapter 2: ROS 2 Fundamentals & Core Programming","docId":"Module 02 ROS2-Basics/2.1-ros2-core-concepts","unlisted":false},{"type":"link","href":"/docs/Module 02 ROS2-Basics/2.2-python-publisher-subscriber","label":"2.2-python-publisher-subscriber","docId":"Module 02 ROS2-Basics/2.2-python-publisher-subscriber","unlisted":false},{"type":"link","href":"/docs/Module 02 ROS2-Basics/2.3-launch-files-orchestration","label":"2.3-launch-files-orchestration","docId":"Module 02 ROS2-Basics/2.3-launch-files-orchestration","unlisted":false}]},{"type":"category","label":"Module 03 saac-Sim","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/Module 03 saac-Sim/3.1-usd-language-of-digital-twins","label":"3.1: NVIDIA Isaac Sim - Universal Scene Description (USD)","docId":"Module 03 saac-Sim/3.1-usd-language-of-digital-twins","unlisted":false},{"type":"link","href":"/docs/Module 03 saac-Sim/3.2-importing-robot-models","label":"3.2-importing-robot-models","docId":"Module 03 saac-Sim/3.2-importing-robot-models","unlisted":false},{"type":"link","href":"/docs/Module 03 saac-Sim/3.3-sim-to-real-transfer-techniques","label":"3.3: NVIDIA Isaac Sim - Sim-to-Real Transfer Techniques","docId":"Module 03 saac-Sim/3.3-sim-to-real-transfer-techniques","unlisted":false}]},{"type":"category","label":"Module 04 GenAI-Robotics","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/Module 04 GenAI-Robotics/4.1-genai-llm-decision-making-controls","label":"4.1: Generative Robotics - LLMs for Robot Decision-Making and Controls","docId":"Module 04 GenAI-Robotics/4.1-genai-llm-decision-making-controls","unlisted":false},{"type":"link","href":"/docs/Module 04 GenAI-Robotics/4.2-genai-vla-models","label":"4.2: Generative Robotics - Vision-Language-Action (VLA) Models","docId":"Module 04 GenAI-Robotics/4.2-genai-vla-models","unlisted":false},{"type":"link","href":"/docs/Module 04 GenAI-Robotics/4.3-genai-voice-to-action-project","label":"4.3: Generative Robotics - \\"Voice-to-Action\\" Project","docId":"Module 04 GenAI-Robotics/4.3-genai-voice-to-action-project","unlisted":false}]},{"type":"category","label":"Module 05 Humanoid-Walking","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/Module 05 Humanoid-Walking/5.1-humanoid-gait-control","label":"5.1: Humanoid Locomotion - Gait Control Phases","docId":"Module 05 Humanoid-Walking/5.1-humanoid-gait-control","unlisted":false},{"type":"link","href":"/docs/Module 05 Humanoid-Walking/5.2-humanoid-physics-and-zmp","label":"5.2: Humanoid Locomotion - Physics of Walking and ZMP","docId":"Module 05 Humanoid-Walking/5.2-humanoid-physics-and-zmp","unlisted":false},{"type":"link","href":"/docs/Module 05 Humanoid-Walking/5.3-humanoid-static-dynamic-walking","label":"5.3: Humanoid Locomotion - Static vs. Dynamic Walking","docId":"Module 05 Humanoid-Walking/5.3-humanoid-static-dynamic-walking","unlisted":false},{"type":"link","href":"/docs/Module 05 Humanoid-Walking/5.4-humanoid-zmp-calculation-example","label":"5.4: Humanoid Locomotion - ZMP Calculation Example","docId":"Module 05 Humanoid-Walking/5.4-humanoid-zmp-calculation-example","unlisted":false}]},{"type":"category","label":"Module 06 Navigation-SLAM","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/Module 06 Navigation-SLAM/6.1-slam-fundamentals","label":"Chapter 6: Navigation & SLAM - SLAM Fundamentals","docId":"Module 06 Navigation-SLAM/6.1-slam-fundamentals","unlisted":false},{"type":"link","href":"/docs/Module 06 Navigation-SLAM/6.2-navigation-obstacle-avoidance-realsense","label":"6.2: Navigation & SLAM - Obstacle Avoidance with Intel RealSense","docId":"Module 06 Navigation-SLAM/6.2-navigation-obstacle-avoidance-realsense","unlisted":false},{"type":"link","href":"/docs/Module 06 Navigation-SLAM/6.4-ros2-nav2-setup-guide","label":"Chapter 6: Navigation & SLAM - ROS 2 Nav2 Setup Guide","docId":"Module 06 Navigation-SLAM/6.4-ros2-nav2-setup-guide","unlisted":false}]},{"type":"category","label":"Module 07 The-Capstone","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/Module 07 The-Capstone/7.1-the-capstone-project","label":"Chapter 7: The Capstone - Conversational Robot","docId":"Module 07 The-Capstone/7.1-the-capstone-project","unlisted":false}]}]},"docs":{"Module 01 Hardware-Lab/1.1-physical-ai-foundations-basics":{"id":"Module 01 Hardware-Lab/1.1-physical-ai-foundations-basics","title":"Chapter 1: Foundations of Physical AI & Lab Setup","description":"Welcome to \\"The Physical AI Lab\\" guidebook! This course delves into the fascinating and demanding intersection of physics simulation, visual perception, and generative AI. To truly master these concepts and build intelligent systems that interact with the physical world, a specialized hardware setup is essential. This guide will walk you through building your personal Physical AI workstation and lab setup, ensuring you have the tools to bring your robotic visions to life.","sidebar":"tutorialSidebar"},"Module 01 Hardware-Lab/1.2-digital-twin-workstation-setup":{"id":"Module 01 Hardware-Lab/1.2-digital-twin-workstation-setup","title":"1.2-digital-twin-workstation-setup","description":"1.2 Building Your Digital Twin Workstation: The Core of Your Physical AI Lab","sidebar":"tutorialSidebar"},"Module 01 Hardware-Lab/1.3-physical-ai-edge-kit":{"id":"Module 01 Hardware-Lab/1.3-physical-ai-edge-kit","title":"1.3-physical-ai-edge-kit","description":"1.3 The Physical AI Edge Kit: Bringing AI to the Real World","sidebar":"tutorialSidebar"},"Module 01 Hardware-Lab/1.4-lab-options-hybrid-architectures":{"id":"Module 01 Hardware-Lab/1.4-lab-options-hybrid-architectures","title":"1.4-lab-options-hybrid-architectures","description":"1.4 Lab Options and Hybrid Architectures: Designing Your Physical AI Development Environment","sidebar":"tutorialSidebar"},"Module 02 ROS2-Basics/2.1-ros2-core-concepts":{"id":"Module 02 ROS2-Basics/2.1-ros2-core-concepts","title":"Chapter 2: ROS 2 Fundamentals & Core Programming","description":"Welcome to the exciting world of ROS 2 (Robot Operating System 2)! This chapter is your foundational guide to understanding and programming with ROS 2, a powerful and flexible framework essential for developing modern robot applications. ROS 2 provides a structured, modular way for various components of a robot system to communicate, coordinate, and work together seamlessly, whether your robot is simulated or physical. By the end of this chapter, you\'ll have a solid grasp of ROS 2\'s core concepts and practical experience in building basic robotic communication systems using Python.","sidebar":"tutorialSidebar"},"Module 02 ROS2-Basics/2.2-python-publisher-subscriber":{"id":"Module 02 ROS2-Basics/2.2-python-publisher-subscriber","title":"2.2-python-publisher-subscriber","description":"2.2 Python Publisher and Subscriber Examples: Your First ROS 2 Communication","sidebar":"tutorialSidebar"},"Module 02 ROS2-Basics/2.3-launch-files-orchestration":{"id":"Module 02 ROS2-Basics/2.3-launch-files-orchestration","title":"2.3-launch-files-orchestration","description":"2.3 Launch Files: Orchestrating Your Robot System","sidebar":"tutorialSidebar"},"Module 03 saac-Sim/3.1-usd-language-of-digital-twins":{"id":"Module 03 saac-Sim/3.1-usd-language-of-digital-twins","title":"3.1: NVIDIA Isaac Sim - Universal Scene Description (USD)","description":"Welcome to Chapter 3 of \\"The Physical AI Lab\\" guidebook! This chapter plunges you into NVIDIA Isaac Sim, a cutting-edge, extensible robotics simulation platform built on NVIDIA Omniverse. Isaac Sim empowers developers to create physically accurate, highly realistic virtual environments crucial for developing, testing, and training AI-powered robots. Here, you\'ll learn the foundational concepts and practical techniques to leverage Isaac Sim for advanced robotics development.","sidebar":"tutorialSidebar"},"Module 03 saac-Sim/3.2-importing-robot-models":{"id":"Module 03 saac-Sim/3.2-importing-robot-models","title":"3.2-importing-robot-models","description":"3.2 Importing Robot Models into Isaac Sim","sidebar":"tutorialSidebar"},"Module 03 saac-Sim/3.3-sim-to-real-transfer-techniques":{"id":"Module 03 saac-Sim/3.3-sim-to-real-transfer-techniques","title":"3.3: NVIDIA Isaac Sim - Sim-to-Real Transfer Techniques","description":"This section focuses on Sim-to-Real transfer, a critical process in robotics development. It involves deploying AI models trained in a simulator onto physical robots, with the goal of minimizing the performance gap between the virtual and real worlds. NVIDIA Isaac Sim provides advanced features to facilitate effective Sim-to-Real transfer, making it a cornerstone for Physical AI development.","sidebar":"tutorialSidebar"},"Module 04 GenAI-Robotics/4.1-genai-llm-decision-making-controls":{"id":"Module 04 GenAI-Robotics/4.1-genai-llm-decision-making-controls","title":"4.1: Generative Robotics - LLMs for Robot Decision-Making and Controls","description":"This section delves into how Large Language Models (LLMs) like OpenAI\'s GPT-4o can be integrated as powerful high-level reasoning and planning modules for robots. While LLMs don\'t directly control robot motors, they are adept at translating human intent into actionable plans or commands that a robot\'s low-level control system can execute. We will also explore crucial implementation considerations, including prompt engineering, function calling, and vital safety guardrails.","sidebar":"tutorialSidebar"},"Module 04 GenAI-Robotics/4.2-genai-vla-models":{"id":"Module 04 GenAI-Robotics/4.2-genai-vla-models","title":"4.2: Generative Robotics - Vision-Language-Action (VLA) Models","description":"Generative AI is rapidly transforming the field of robotics, enabling robots to understand, reason, and act in complex, unstructured environments in ways previously thought impossible. This section explores the exciting realm of Generative Robotics, focusing on Vision-Language-Action (VLA) models \u2013 a new paradigm bridging perception, language, and control for intelligent robots.","sidebar":"tutorialSidebar"},"Module 04 GenAI-Robotics/4.3-genai-voice-to-action-project":{"id":"Module 04 GenAI-Robotics/4.3-genai-voice-to-action-project","title":"4.3: Generative Robotics - \\"Voice-to-Action\\" Project","description":"This section outlines a practical \\"Voice-to-Action\\" project, combining speech recognition with LLM-powered decision-making to allow human users to command a robot using natural voice instructions. This project provides an excellent hands-on opportunity to integrate cutting-edge generative AI models with real-world robotics, demonstrating how natural human-robot interaction can be achieved through advanced language and vision capabilities.","sidebar":"tutorialSidebar"},"Module 05 Humanoid-Walking/5.1-humanoid-gait-control":{"id":"Module 05 Humanoid-Walking/5.1-humanoid-gait-control","title":"5.1: Humanoid Locomotion - Gait Control Phases","description":"Building upon the concepts of static and dynamic walking, this section delves into the alternating phases that characterize the walking gait of a bipedal robot: the Double Support Phase and the Single Support (Swing) Phase. Understanding these phases is crucial for designing and controlling stable and efficient humanoid locomotion.","sidebar":"tutorialSidebar"},"Module 05 Humanoid-Walking/5.2-humanoid-physics-and-zmp":{"id":"Module 05 Humanoid-Walking/5.2-humanoid-physics-and-zmp","title":"5.2: Humanoid Locomotion - Physics of Walking and ZMP","description":"Humanoid locomotion, particularly bipedal walking, is a complex feat of engineering and control, mimicking the intricate balance and movement strategies of biological systems. Unlike wheeled robots that maintain stability through a wide base of support, humanoids inherently face a continuous challenge of balance, often described as \\"controlled falling.\\" This section delves into the fundamental physics and stability concepts behind bipedal walking, focusing on the Inverted Pendulum Model and the critical Zero Moment Point (ZMP).","sidebar":"tutorialSidebar"},"Module 05 Humanoid-Walking/5.3-humanoid-static-dynamic-walking":{"id":"Module 05 Humanoid-Walking/5.3-humanoid-static-dynamic-walking","title":"5.3: Humanoid Locomotion - Static vs. Dynamic Walking","description":"Building on the understanding of the Inverted Pendulum Model and ZMP, this section elaborates on the two fundamental types of bipedal locomotion: static walking and dynamic walking. The distinction between these two approaches is crucial for designing efficient and natural-looking humanoid gaits.","sidebar":"tutorialSidebar"},"Module 05 Humanoid-Walking/5.4-humanoid-zmp-calculation-example":{"id":"Module 05 Humanoid-Walking/5.4-humanoid-zmp-calculation-example","title":"5.4: Humanoid Locomotion - ZMP Calculation Example","description":"Building upon the theoretical understanding of the Zero Moment Point (ZMP), this section provides a conceptual code snippet and an extended practice exercise for calculating a simplified ZMP. Understanding this calculation is fundamental for implementing stable bipedal locomotion control strategies.","sidebar":"tutorialSidebar"},"Module 06 Navigation-SLAM/6.1-slam-fundamentals":{"id":"Module 06 Navigation-SLAM/6.1-slam-fundamentals","title":"Chapter 6: Navigation & SLAM - SLAM Fundamentals","description":"6.1.1 Understanding Simultaneous Localization and Mapping (SLAM)","sidebar":"tutorialSidebar"},"Module 06 Navigation-SLAM/6.2-navigation-obstacle-avoidance-realsense":{"id":"Module 06 Navigation-SLAM/6.2-navigation-obstacle-avoidance-realsense","title":"6.2: Navigation & SLAM - Obstacle Avoidance with Intel RealSense","description":"Beyond simply knowing where you are and what the environment looks like (SLAM), a robot must also safely navigate through it. This section focuses on obstacle avoidance using depth sensors, specifically the Intel RealSense Depth Camera. We will explore how these cameras can be integrated with robotics platforms like ArduPilot to enable autonomous robots to detect and react to obstacles, ensuring safer navigation.","sidebar":"tutorialSidebar"},"Module 06 Navigation-SLAM/6.4-ros2-nav2-setup-guide":{"id":"Module 06 Navigation-SLAM/6.4-ros2-nav2-setup-guide","title":"Chapter 6: Navigation & SLAM - ROS 2 Nav2 Setup Guide","description":"6.4.1 Guide to Setting Up the Nav2 Stack in ROS 2","sidebar":"tutorialSidebar"},"Module 07 The-Capstone/7.1-the-capstone-project":{"id":"Module 07 The-Capstone/7.1-the-capstone-project","title":"Chapter 7: The Capstone - Conversational Robot","description":"This capstone project brings together all the concepts learned in the \\"Teaching Physical AI & Humanoid Robotics Course\\" to build a conversational robot. The goal is to create an embodied AI that can understand natural language, process information, and perform actions in a physical or simulated environment.","sidebar":"tutorialSidebar"}}}}')}}]);