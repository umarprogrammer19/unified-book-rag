<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-Module 06 Navigation-SLAM/6.2-navigation-obstacle-avoidance-realsense" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">6.2: Navigation &amp; SLAM - Obstacle Avoidance with Intel RealSense | Teaching Physical AI &amp; Humanoid Robotics</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://your-docusaurus-site.example.com/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://your-docusaurus-site.example.com/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://your-docusaurus-site.example.com/docs/Module 06 Navigation-SLAM/6.2-navigation-obstacle-avoidance-realsense"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="6.2: Navigation &amp; SLAM - Obstacle Avoidance with Intel RealSense | Teaching Physical AI &amp; Humanoid Robotics"><meta data-rh="true" name="description" content="Beyond simply knowing where you are and what the environment looks like (SLAM), a robot must also safely navigate through it. This section focuses on obstacle avoidance using depth sensors, specifically the Intel RealSense Depth Camera. We will explore how these cameras can be integrated with robotics platforms like ArduPilot to enable autonomous robots to detect and react to obstacles, ensuring safer navigation."><meta data-rh="true" property="og:description" content="Beyond simply knowing where you are and what the environment looks like (SLAM), a robot must also safely navigate through it. This section focuses on obstacle avoidance using depth sensors, specifically the Intel RealSense Depth Camera. We will explore how these cameras can be integrated with robotics platforms like ArduPilot to enable autonomous robots to detect and react to obstacles, ensuring safer navigation."><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://your-docusaurus-site.example.com/docs/Module 06 Navigation-SLAM/6.2-navigation-obstacle-avoidance-realsense"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/docs/Module 06 Navigation-SLAM/6.2-navigation-obstacle-avoidance-realsense" hreflang="en"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/docs/Module 06 Navigation-SLAM/6.2-navigation-obstacle-avoidance-realsense" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"6.2: Navigation & SLAM - Obstacle Avoidance with Intel RealSense","item":"https://your-docusaurus-site.example.com/docs/Module 06 Navigation-SLAM/6.2-navigation-obstacle-avoidance-realsense"}]}</script><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Teaching Physical AI &amp; Humanoid Robotics RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Teaching Physical AI &amp; Humanoid Robotics Atom Feed"><link rel="stylesheet" href="/assets/css/styles.9c53a5ce.css">
<script src="/assets/js/runtime~main.b52d3cf6.js" defer="defer"></script>
<script src="/assets/js/main.5c2aef56.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Teaching Physical AI &amp; Humanoid Robotics</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/Module 01 Hardware-Lab/1.1-physical-ai-foundations-basics">Tutorial</a><a class="navbar__item navbar__link" href="/blog">Blog</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/Module 01 Hardware-Lab/1.1-physical-ai-foundations-basics"><span title="Module 01 Hardware-Lab" class="categoryLinkLabel_W154">Module 01 Hardware-Lab</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/Module 02 ROS2-Basics/2.1-ros2-core-concepts"><span title="Module 02 ROS2-Basics" class="categoryLinkLabel_W154">Module 02 ROS2-Basics</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/Module 03 saac-Sim/3.1-usd-language-of-digital-twins"><span title="Module 03 saac-Sim" class="categoryLinkLabel_W154">Module 03 saac-Sim</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/Module 04 GenAI-Robotics/4.1-genai-llm-decision-making-controls"><span title="Module 04 GenAI-Robotics" class="categoryLinkLabel_W154">Module 04 GenAI-Robotics</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/Module 05 Humanoid-Walking/5.1-humanoid-gait-control"><span title="Module 05 Humanoid-Walking" class="categoryLinkLabel_W154">Module 05 Humanoid-Walking</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/Module 06 Navigation-SLAM/6.1-slam-fundamentals"><span title="Module 06 Navigation-SLAM" class="categoryLinkLabel_W154">Module 06 Navigation-SLAM</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Module 06 Navigation-SLAM/6.1-slam-fundamentals"><span title="Chapter 6: Navigation &amp; SLAM - SLAM Fundamentals" class="linkLabel_WmDU">Chapter 6: Navigation &amp; SLAM - SLAM Fundamentals</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/Module 06 Navigation-SLAM/6.2-navigation-obstacle-avoidance-realsense"><span title="6.2: Navigation &amp; SLAM - Obstacle Avoidance with Intel RealSense" class="linkLabel_WmDU">6.2: Navigation &amp; SLAM - Obstacle Avoidance with Intel RealSense</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Module 06 Navigation-SLAM/6.4-ros2-nav2-setup-guide"><span title="Chapter 6: Navigation &amp; SLAM - ROS 2 Nav2 Setup Guide" class="linkLabel_WmDU">Chapter 6: Navigation &amp; SLAM - ROS 2 Nav2 Setup Guide</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/Module 07 The-Capstone/7.1-the-capstone-project"><span title="Module 07 The-Capstone" class="categoryLinkLabel_W154">Module 07 The-Capstone</span></a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Module 06 Navigation-SLAM</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">6.2: Navigation &amp; SLAM - Obstacle Avoidance with Intel RealSense</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>6.2: Navigation &amp; SLAM - Obstacle Avoidance with Intel RealSense</h1></header>
<p>Beyond simply knowing where you are and what the environment looks like (SLAM), a robot must also safely navigate through it. This section focuses on <strong>obstacle avoidance</strong> using depth sensors, specifically the Intel RealSense Depth Camera. We will explore how these cameras can be integrated with robotics platforms like ArduPilot to enable autonomous robots to detect and react to obstacles, ensuring safer navigation.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-obstacle-avoidance-with-intel-realsense-depth-camera">2. Obstacle Avoidance with Intel RealSense Depth Camera<a href="#2-obstacle-avoidance-with-intel-realsense-depth-camera" class="hash-link" aria-label="Direct link to 2. Obstacle Avoidance with Intel RealSense Depth Camera" title="Direct link to 2. Obstacle Avoidance with Intel RealSense Depth Camera" translate="no">​</a></h2>
<p>The Intel RealSense Depth Camera, particularly models like the D435 or D435i (as mentioned in Chapter 1 as part of the Edge Kit), can be effectively integrated with robotics platforms for autonomous obstacle avoidance. This allows robots to intelligently perceive their immediate surroundings and alter their path to prevent collisions.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="hardware-and-setup">Hardware and Setup:<a href="#hardware-and-setup" class="hash-link" aria-label="Direct link to Hardware and Setup:" title="Direct link to Hardware and Setup:" translate="no">​</a></h3>
<p>Proper hardware integration and mounting are crucial for reliable depth sensing and obstacle avoidance.</p>
<ul>
<li class=""><strong>Camera:</strong> Intel RealSense D435 or D435i depth camera. These cameras provide both RGB (color) and depth (distance) data streams.</li>
<li class=""><strong>Companion Computer:</strong> An UP Squared companion computer is often recommended for more robust processing, as platforms like Raspberry Pi 4 might not be directly supported or sufficiently powerful for certain RealSense integrations and the processing required.</li>
<li class=""><strong>Mounting:</strong>
<ul>
<li class="">The camera should be mounted facing forward to provide a clear view of the robot&#x27;s immediate path.</li>
<li class="">Ideally, use vibration isolation to minimize noise in the depth data, which can be caused by robot movement.</li>
<li class="">Connect the RealSense camera via a USB3 port on the companion computer to ensure sufficient bandwidth for high-resolution depth streams.</li>
</ul>
</li>
<li class=""><strong>Serial Connection (for Autopilot Integration):</strong> If integrating with an autopilot (like ArduPilot), the companion computer&#x27;s serial port needs to be linked to an autopilot telemetry port (e.g., <code>Telem1</code>, <code>Telem2</code>). This allows for low-latency communication of obstacle data to the flight controller.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="software-and-configuration-example-ardupilot-integration">Software and Configuration (Example: ArduPilot Integration):<a href="#software-and-configuration-example-ardupilot-integration" class="hash-link" aria-label="Direct link to Software and Configuration (Example: ArduPilot Integration):" title="Direct link to Software and Configuration (Example: ArduPilot Integration):" translate="no">​</a></h3>
<p>This section outlines a typical software setup for integrating RealSense with ArduPilot for obstacle avoidance. While specifics may vary, the general principles apply to other robotics frameworks as well.</p>
<ol>
<li class="">
<p><strong>Companion Computer OS Setup (APSync):</strong></p>
<ul>
<li class="">Install APSync (ArduPilot&#x27;s companion computer image) on the UP Squared by downloading and restoring the appropriate APSync image (e.g., <code>apsync-up2-d435i-yyyymmdd.tar.xz</code>) using a tool like Clonezilla via Tuxboot.</li>
<li class="">APSync provides a pre-configured environment with necessary drivers and utilities.</li>
</ul>
</li>
<li class="">
<p><strong>RealSense Firmware Update:</strong></p>
<ul>
<li class="">Ensure the RealSense camera firmware is updated to the latest stable version (e.g., 5.12.8.200 or later). Firmware updates often include performance improvements and bug fixes critical for reliable operation.</li>
</ul>
</li>
<li class="">
<p><strong>ArduPilot Parameter Settings:</strong></p>
<ul>
<li class="">Connect to your ArduPilot flight controller using a ground control station (e.g., Mission Planner, QGroundControl) and configure the following parameters:<!-- -->
<ul>
<li class=""><code>SERIALx_PROTOCOL = 2</code> (where <code>x</code> is the serial port number, typically 2 for <code>Telem2</code>) to enable MAVLink2 communication, a standard protocol for UAVs.</li>
<li class=""><code>SERIALx_BAUD = 921</code> (921600 baud) for the serial communication speed, ensuring fast data transfer.</li>
<li class=""><code>PRX1_TYPE = 2</code> to enable the proximity sensor input from the companion computer.</li>
<li class=""><code>AVOID_ENABLE = 7</code> to enable various avoidance behaviors (e.g., slowing down, stopping, moving around obstacles).</li>
<li class="">Tune <code>AVOID_MARGIN</code> (how far from an obstacle to start avoiding), <code>AVOID_BEHAVE</code> (avoidance strategy), <code>AVOID_DIST_MAX</code> (maximum distance to consider an obstacle), and <code>AVOID_ANGLE_MAX</code> (field of view for avoidance) to define the desired avoidance parameters based on your robot&#x27;s dynamics and environment.</li>
</ul>
</li>
<li class=""><strong>Reboot</strong> the autopilot after configuration changes to apply them.</li>
</ul>
</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="how-it-works-software-logic">How it Works (Software Logic):<a href="#how-it-works-software-logic" class="hash-link" aria-label="Direct link to How it Works (Software Logic):" title="Direct link to How it Works (Software Logic):" translate="no">​</a></h3>
<ol>
<li class=""><strong>Depth Data Processing Script:</strong> The system typically uses a Python script (e.g., <code>realsense_obstacle_avoidance.py</code>) running on the companion computer. This script performs the following:<!-- -->
<ul>
<li class="">Acquires raw depth images from the RealSense camera.</li>
<li class="">Applies filters to reduce noise and fill &quot;black holes&quot; (areas with no valid depth data) in the depth map.</li>
<li class="">Processes the camera&#x27;s horizontal field of view into a series of <code>N</code> rays (e.g., 72 rays), calculating the minimum distance to an obstacle along each ray. It may compensate for vehicle pitch to ensure accurate ground projection.</li>
<li class="">Sends <code>OBSTACLE_DISTANCE</code> MAVLink messages to the autopilot at a high rate (e.g., 10Hz or more), providing a real-time representation of the surrounding obstacles.</li>
</ul>
</li>
<li class=""><strong>Autopilot Response:</strong> The autopilot receives these <code>OBSTACLE_DISTANCE</code> messages and, based on the <code>AVOID_</code> parameters, executes avoidance maneuvers (e.g., adjusting velocity commands, changing path).</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="verification-and-testing">Verification and Testing:<a href="#verification-and-testing" class="hash-link" aria-label="Direct link to Verification and Testing:" title="Direct link to Verification and Testing:" translate="no">​</a></h3>
<p>Thorough testing is crucial to ensure the obstacle avoidance system functions reliably and safely.</p>
<ul>
<li class=""><strong>Ground Test (Mission Planner):</strong>
<ul>
<li class="">Use Mission Planner&#x27;s &quot;Mavlink Inspector&quot; to confirm that <code>OBSTACLE_DISTANCE</code> messages are being received (around 15 Hz is a good rate) and that their content is meaningful.</li>
<li class="">Check the &quot;Proximity view&quot; in Mission Planner, which should accurately show the distance to the nearest obstacle within defined angular sectors (e.g., 45-degree arcs).</li>
<li class="">Physically place objects in front of the camera and observe how the reported distances change.</li>
</ul>
</li>
<li class=""><strong>Flight Test (for UAVs) / Movement Test (for Ground Robots):</strong>
<ul>
<li class="">In a controlled environment, operate the robot (e.g., in <code>AltHold</code> or <code>Loiter</code> mode for a drone, or a simple teleoperated mode for a ground robot) and move it towards obstacles.</li>
<li class="">Observe if the vehicle stops, slows down, or slides at the configured <code>AVOID_MARGIN</code> distance when approaching obstacles.</li>
<li class="">Analyze DataFlash logs (<code>PRX.CAn</code> for angle, <code>PRX.CDist</code> for distance) after the test to review the proximity data and verify the avoidance behavior.</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="project-idea-simple-depth-based-collision-detection-in-ros-2">Project Idea: Simple Depth-Based Collision Detection in ROS 2<a href="#project-idea-simple-depth-based-collision-detection-in-ros-2" class="hash-link" aria-label="Direct link to Project Idea: Simple Depth-Based Collision Detection in ROS 2" title="Direct link to Project Idea: Simple Depth-Based Collision Detection in ROS 2" translate="no">​</a></h3>
<p><strong>Goal:</strong> Implement a basic collision detection system for a simulated robot using a RealSense-like depth camera in ROS 2.</p>
<ol>
<li class=""><strong>Simulated Robot Setup:</strong> In Gazebo or Isaac Sim, spawn a simple robot (e.g., Turtlebot3) with a simulated depth camera. Ensure it publishes <code>sensor_msgs/PointCloud2</code> or <code>sensor_msgs/Image</code> (depth) messages.</li>
<li class=""><strong>ROS 2 Node for Depth Processing:</strong> Create a ROS 2 Python node that subscribes to the depth camera topic.</li>
<li class=""><strong>Collision Logic:</strong> Within the node&#x27;s callback, process the depth data. For a simple approach, calculate the minimum depth within a defined前方 (front) region of interest. If this minimum depth falls below a threshold (e.g., 0.5 meters), publish a warning message (e.g., to a <code>/collision_warning</code> topic) or a <code>geometry_msgs/Twist</code> message with zero velocity to halt the robot.</li>
<li class=""><strong>Visualization:</strong> Use RViz to visualize the depth data and the robot&#x27;s movement. You can also add a custom display to show the detected minimum distance or the collision warning.</li>
</ol>
<p>This project will provide hands-on experience with depth camera data processing and implementing a fundamental safety mechanism for autonomous robots.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/Module 06 Navigation-SLAM/6.2-navigation-obstacle-avoidance-realsense.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/Module 06 Navigation-SLAM/6.1-slam-fundamentals"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Chapter 6: Navigation &amp; SLAM - SLAM Fundamentals</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/Module 06 Navigation-SLAM/6.4-ros2-nav2-setup-guide"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Chapter 6: Navigation &amp; SLAM - ROS 2 Nav2 Setup Guide</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#2-obstacle-avoidance-with-intel-realsense-depth-camera" class="table-of-contents__link toc-highlight">2. Obstacle Avoidance with Intel RealSense Depth Camera</a><ul><li><a href="#hardware-and-setup" class="table-of-contents__link toc-highlight">Hardware and Setup:</a></li><li><a href="#software-and-configuration-example-ardupilot-integration" class="table-of-contents__link toc-highlight">Software and Configuration (Example: ArduPilot Integration):</a></li><li><a href="#how-it-works-software-logic" class="table-of-contents__link toc-highlight">How it Works (Software Logic):</a></li><li><a href="#verification-and-testing" class="table-of-contents__link toc-highlight">Verification and Testing:</a></li><li><a href="#project-idea-simple-depth-based-collision-detection-in-ros-2" class="table-of-contents__link toc-highlight">Project Idea: Simple Depth-Based Collision Detection in ROS 2</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/Module 01 Hardware-Lab/1.1-physical-ai-foundations-basics">Tutorial</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://x.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 My Project, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>